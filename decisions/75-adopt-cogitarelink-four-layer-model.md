 # Adopt CogitareLink Four-Layer Model

 Discussion: https://github.com/crcresearch/earth616_ontology/issues/20

 ## Status
 _Proposed_

 ## Decision
 Reorganize DSCDO repository into four layers: Layer 0 (Context), Layer 1 (Ontology Modules), Layer 2 (Shapes & Rules), Layer 3 (Data).

 ## Context
 CogitareLink is a semantic-memory substrate for agentic LLM systems that:
 
 - Stores JSON-LD 1.1 data, runs SHACL/SPARQL rules to derive new facts, caches everything, and records provenance for every triple.
 - Uses a minimal Python micro-kernel (~600 LOC); all domain logic lives in data artifacts (contexts, ontologies, shapes, rules) or is generated by the LLM.

 To support predictable agent workflows, knowledge artifacts are organized into four layers:
 
 - Layer 0 (Context): JSON-LD context files (*.context.jsonld), ~1–5 KB, always loaded in-prompt to supply prefix↔IRI mappings and term definitions.
 - Layer 1 (Ontology Modules): Turtle/JSON-LD ontology files (ontology.ttl/.jsonld), ~20–200 KB, fetched on-demand for class/property navigation.
 - Layer 2 (Shapes & Rules): SHACL shape and rule files (shapes.ttl, rules.ttl), ~30–300 KB, fetched on-demand for validation and inference.
 - Layer 3 (Data): JSON-LD instance documents (*.jsonld), ~5 KB–1 MB, streamed to the agent; each instance links to shapes via ex:hasShape.

 These layers interoperate as follows:
 
 1. Data documents reference shapes (ex:hasShape → shapes.ttl).
 2. Shapes import ontology modules via owl:imports.
 3. Ontology modules rely on the context layer for prefix definitions.

 Aligning DSCDO to this model ensures seamless integration with CogitareLink’s agent workflows and tooling.

 ## Consequences
 - Clear separation of concerns and better LLM tooling.
 - Initial overhead reorganizing repository structure.